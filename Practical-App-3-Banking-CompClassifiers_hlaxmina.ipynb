{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical Application III: Comparing Classifiers\n",
    "\n",
    "**Overview**: In this practical application, your goal is to compare the performance of the classifiers we encountered in this section, namely K Nearest Neighbor, Logistic Regression, Decision Trees, and Support Vector Machines.  We will utilize a dataset related to marketing bank products over the telephone.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started\n",
    "\n",
    "Our dataset comes from the UCI Machine Learning repository [link](https://archive.ics.uci.edu/ml/datasets/bank+marketing).  The data is from a Portugese banking institution and is a collection of the results of multiple marketing campaigns.  We will make use of the article accompanying the dataset [here](CRISP-DM-BANK.pdf) for more information on the data and features.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1: Understanding the Data\n",
    "\n",
    "To gain a better understanding of the data, please read the information provided in the UCI link above, and examine the **Materials and Methods** section of the paper.  How many marketing campaigns does this data represent?\n",
    "\n",
    "<font color=darkred>\n",
    "The Bank Marketing dataset, sourced from the UCI Machine Learning Repository, originates from a Portuguese bank's direct marketing campaigns. These campaigns aimed to promote term deposit subscriptions through telemarketing calls. The dataset includes 45,211 instances (after removing duplicates) and 17 attributes capturing customer demographics, campaign details, and economic indicators. The data was collected from a series of telemarketing campaigns conducted by the bank. The response variable (\"y\") is binary, indicating whether a client subscribed to a term deposit (yes/no).\n",
    "\n",
    "The goal is to predict whether a client will subscribe to a term deposit (\"yes\") or not (\"no\"). This prediction can help the bank optimize its marketing strategies and allocate resources more effectively.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2: Read in the Data\n",
    "\n",
    "Use pandas to read in the dataset `bank-additional-full.csv` and assign to a meaningful variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder, StandardScaler, OrdinalEncoder,  LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, roc_curve, f1_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import SMOTE                # For oversampling minority class \n",
    "from imblearn.under_sampling import RandomUnderSampler  # For undersampling majority class\n",
    "from imblearn.metrics import specificity_score\n",
    "\n",
    "from sklearn.metrics import RocCurveDisplay, roc_curve, auc\n",
    "\n",
    "from plot_helpers import render_plot\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the bank data\n",
    "bankdata = pd.read_csv('data/bank-additional-full.csv', sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3: Understanding the Features\n",
    "\n",
    "\n",
    "Examine the data description below, and determine if any of the features are missing values or need to be coerced to a different data type.\n",
    "\n",
    "\n",
    "```\n",
    "Input variables:\n",
    "# bank client data:\n",
    "1 - age (numeric)\n",
    "2 - job : type of job (categorical: 'admin.','blue-collar','entrepreneur','housemaid','management','retired','self-employed','services','student','technician','unemployed','unknown')\n",
    "3 - marital : marital status (categorical: 'divorced','married','single','unknown'; note: 'divorced' means divorced or widowed)\n",
    "4 - education (categorical: 'basic.4y','basic.6y','basic.9y','high.school','illiterate','professional.course','university.degree','unknown')\n",
    "5 - default: has credit in default? (categorical: 'no','yes','unknown')\n",
    "6 - housing: has housing loan? (categorical: 'no','yes','unknown')\n",
    "7 - loan: has personal loan? (categorical: 'no','yes','unknown')\n",
    "# related with the last contact of the current campaign:\n",
    "8 - contact: contact communication type (categorical: 'cellular','telephone')\n",
    "9 - month: last contact month of year (categorical: 'jan', 'feb', 'mar', ..., 'nov', 'dec')\n",
    "10 - day_of_week: last contact day of the week (categorical: 'mon','tue','wed','thu','fri')\n",
    "11 - duration: last contact duration, in seconds (numeric). Important note: this attribute highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.\n",
    "# other attributes:\n",
    "12 - campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "13 - pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "14 - previous: number of contacts performed before this campaign and for this client (numeric)\n",
    "15 - poutcome: outcome of the previous marketing campaign (categorical: 'failure','nonexistent','success')\n",
    "# social and economic context attributes\n",
    "16 - emp.var.rate: employment variation rate - quarterly indicator (numeric)\n",
    "17 - cons.price.idx: consumer price index - monthly indicator (numeric)\n",
    "18 - cons.conf.idx: consumer confidence index - monthly indicator (numeric)\n",
    "19 - euribor3m: euribor 3 month rate - daily indicator (numeric)\n",
    "20 - nr.employed: number of employees - quarterly indicator (numeric)\n",
    "\n",
    "Output variable (desired target):\n",
    "21 - y - has the client subscribed a term deposit? (binary: 'yes','no')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_rows = bankdata.duplicated().sum()\n",
    "print(f'Number of duplicate rows: {duplicate_rows}')\n",
    "\n",
    "# Remove duplicate rows\n",
    "bankdata = bankdata.drop_duplicates()\n",
    "print(f'Dataset shape after removing duplicates: {bankdata.shape}')\n",
    "\n",
    "# Check for null values\n",
    "null_values = bankdata.isnull().sum()\n",
    "print(f'Null values in each column:\\n{null_values}')\n",
    "\n",
    "# Since duration is already deamed to be a predictor of success, and can't predict how long a customer service agent may talk to the client\n",
    "# how many calls would require to get the answer about deposit, we will drop these feature from the analysis.\n",
    "bankdata.drop(['campaign','duration', 'pdays'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find outliers in the data using the IQR method\n",
    "numerical_columns = bankdata.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "df_numerical = bankdata[numerical_columns]\n",
    "\n",
    "Q1 = df_numerical.quantile(0.25)\n",
    "Q3 = df_numerical.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "total_outliers = ((df_numerical < (Q1 - 1.5 * IQR)) | (df_numerical > (Q3 + 1.5 * IQR))).sum()\n",
    "print(f'Outliers in each column:\\n{total_outliers}')\n",
    "\n",
    "outliers = ((df_numerical < (Q1 - 1.5 * IQR)) | (df_numerical > (Q3 + 1.5 * IQR)))\n",
    "\n",
    "\n",
    "# Remove outliers from the dataset\n",
    "print(f'Original dataset shape: {bankdata.shape}')\n",
    "print(f'Removing outliers will change the dataset shape to : {bankdata[~outliers.any(axis=1)].shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Even though there are outliers in a few columns such as duration, campaign, pdays, previous. This has been ignored as standard scalar method will be used later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review the values in the categorical columns \n",
    "\n",
    "for column in bankdata.select_dtypes(include='object').columns:\n",
    "    print(f\"Unique values in {column}: {bankdata[column].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Apart from education column, it does not appear the values in categorical columns needs to be co-erced into some other values. For the education column - there does appear to be an order in the level education starting with illeterate, 4yr, 6y, 9y, high school, professional course, degree, unknown. We could consider creating an ordinal transformer for this column in our pipeline, however i am not sure if this order makes a difference in determining the success of the campaign</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the distribution of the target variable\n",
    "\n",
    "ax = sns.histplot(bankdata['y'])\n",
    "\n",
    "render_plot(ax, 'Distribution of the target variable', xlabel='success', ylabel='count',\n",
    "            plotname='target_variable_distribution.png', rotation=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "- bank-additional-full.csv dataset contains both categorical and numerical features.\n",
    "- No explicit missing values (NaN). Categorical values labeled as \"unknown\" are present and requires proper handling\n",
    "- The target variable (y) is imbalanced, meaning more customers did not subscribe to the term deposit than those who did.\n",
    "- Data set is imbalanced. Majority of the clients (~88%) didnt subscribe (y = \"no\") to the term deposit. Using SMOTE technique can help here.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of numerical columns\n",
    "\n",
    "num_cols = 4        # Define the number of rows and columns for the grid\n",
    "num_rows = (len(numerical_columns) + num_cols - 1) // num_cols\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 5))\n",
    "\n",
    "# Flatten the axes array for easy iteration\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(numerical_columns):\n",
    "    ax = sns.histplot(x=bankdata[column], ax=axes[i], hue=bankdata['y'], kde=True)\n",
    "    ax.set_title(f'{column}')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>**Distributions of Numerical Columns**\n",
    "\n",
    "<font color=darkred>\n",
    "- Age: The distribution of ages is skewed to the right. A larger proportion of younger people (20-40) are not subscribed while the likelihood increases at age 40 and decreases after.\n",
    "\n",
    "- Previous: Most clients have not been contacted in a previous campaign (0). Subscriptions appear to be slightly higher among those with \"previous\" campaign contact, but the vast majority are clustered at 0.\n",
    "\n",
    "- emp.var.rate (Employment Variation Rate): The variable has modes at roughly -3, -2, 0, and +1. Subscriptions appear higher when the employment variation rate is at -3 and decreases when it is at +1.\n",
    "\n",
    "- cons.price.idx (Consumer Price Index): This variable shows several clusters. Subscriptions seem very marginally higher when cons.price.idx is lower.\n",
    "\n",
    "- cons.conf.idx (Consumer Confidence Index): This variable is clustered, with the highest counts at more negative values. Subscriptions appear slightly more prevalent when the consumer confidence index is less negative.\n",
    "\n",
    "- euribor3m (Euribor 3 Month Rate): The distribution is concentrated at higher rates (around 4-5). Subscriptions are noticeably higher when the euribor3m rate is lower (around 1).\n",
    "\n",
    "- nr.employed (Number of Employees): This has distinct clusters. Subscriptions seem to be somewhat higher when the number of employees is lower (around 5000-5100).\n",
    "</font>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(data = bankdata['euribor3m'], x=)\n",
    "\n",
    "# Calculate the mean of 'y_numeric' grouped by 'euribor3m'\n",
    "euribor3m_mean = bankdata.groupby('y')['euribor3m'].mean()\n",
    "euribor3m_mean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Success with customers purchasing bank deposits seems to be higher when the Euribor rates are lower. This is counter intuititve, since a higher Euribor rate would imply higher term deposit rate and hence higher bank deposit acceptance rate. This requires further discussion with a domain expert to understand these rates and its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare age column with the target variable\n",
    "\n",
    "sns.boxplot(y=bankdata['age'], x=bankdata['y'], hue=bankdata['y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankdata['y_numeric'] = bankdata['y'].apply(lambda x: 1 if x == 'yes' else 0)\n",
    "\n",
    "before_60 = round((bankdata[bankdata.age < 60].y_numeric.sum()/sum(bankdata.age < 60))*100, 2)\n",
    "after_60 = round((bankdata[bankdata.age > 60].y_numeric.sum()/sum(bankdata.age > 60))*100, 2)\n",
    "\n",
    "print('Before 60: {}% subscribed\\nAfter 60: {}% subscribed'.format(before_60, after_60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "    \n",
    "- Median Age: The median age of those who subscribed (\"yes\") appears to be slightly higher than those who did not subscribe (\"no\").\n",
    "- Age Distribution: The age distribution is fairly similar between the two groups, however, there are outliers.\n",
    "- Outliers: Both groups have a large number of outliers on the higher end of the age range. This indicates that there are many older individuals in the dataset, and their age doesn't necessarily preclude them from either subscribing or not subscribing.\n",
    "- Range: The box representing those who did subscribe is overall slightly higher than the box for those who did not subscribe.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare nr.employed in the bank column with the target variable\n",
    "\n",
    "ax = sns.boxplot(y=bankdata['nr.employed'], x=bankdata['y'], hue=bankdata['y'])\n",
    "ax.set_xlabel('Success')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "- Median nr.employed: The median number of employees is higher for the group that did not subscribe (\"no\") compared to the group that did subscribe (\"yes\").\n",
    "- Distribution: The distribution of \"nr.employed\" is noticeably different between the two groups.\n",
    "- Quartiles: The entire boxplot for the \"no\" group sits higher on the y-axis than the \"yes\" group. This means that, in general, the number of employees tends to be higher for those who did not subscribe.\n",
    "- Range: The ranges also differ somewhat.\n",
    "A lower number of employees (\"nr.employed\") seems to be correlated with a higher likelihood of subscription (\"yes\").\n",
    "\n",
    "A higher number of employees (\"nr.employed\") seems to be correlated with a lower likelihood of subscription (\"no\").\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the correlation between numerical columns\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.heatmap(bankdata.corr(numeric_only=True), annot=True, cmap='coolwarm', vmin=-1, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    " \n",
    "-  Positive Correlation\n",
    "- emp.var.rate and euribor3m: A very strong positive correlation (0.97). This makes sense, as both are indicators of the economic climate. When employment variation rates are high, interest rates tend to be high as well.\n",
    "- emp.var.rate and nr.employed: Also a strong positive correlation (0.91). As employment rates increase, so does the number of people employed.\n",
    "- euribor3m and nr.employed: Strong positive correlation (0.95). This is also logical, as both are related to the overall economic situation.\n",
    "- emp.var.rate and cons.price.idx: Positive correlation (0.78). This suggests that as employment variation rates increase, so do consumer prices.\n",
    "- euribor3m and cons.price.idx: Positive correlation (0.69). Similarly, as interest rates increase, so do consumer prices.\n",
    "\n",
    "- Negative Correlations\n",
    "\n",
    "- emp.var.rate and previous: Moderate negative correlation (-0.42). This might indicate that the more contacts in previous marketing campaigns, the lower the employment variation rate. This is counterintuitive and may be more related to the timing of the campaigns and general economic trends.\n",
    "- euribor3m and previous: Moderate negative correlation (-0.45). Similar to the emp.var.rate, this suggests that as interest rates increase, the effectiveness of previous campaigns decreases.\n",
    "nr.employed and previous: Moderate negative correlation (-0.50). The more people employed the less effective prior campaigns were.\n",
    "- emp.var.rate and y_numeric: Weak negative correlation (-0.3). Higher employment rate correlates with less likelihood of subscribing.\n",
    "- euribor3m and y_numeric: Weak negative correlation (-0.31). High interest rate correlated with less likelihood of subscribing.\n",
    "- nr.employed and y_numeric: Weak negative correlation (-0.35). Higher employment correlated with less likelihood of subscribing.\n",
    "\n",
    "- Weak Correlation\n",
    "- age has very weak correlations with all variables.\n",
    "- cons.conf.idx has weak correlations with all variables.\n",
    "- cons.price.idx has weak correlations with all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Define the categorical columns\n",
    "categorical_columns = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the categorical variables with y values normalized\n",
    "\n",
    "# Define the number of rows and columns for the grid\n",
    "num_cols = 4\n",
    "num_rows = (len(categorical_columns) + num_cols - 1) // num_cols\n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, num_rows * 5))\n",
    "\n",
    "# Flatten the axes array for easy iterationa\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, column in enumerate(categorical_columns):\n",
    "    # Calculate the ratio\n",
    "    ratio = bankdata.groupby([column, 'y']).size().unstack().apply(lambda x: x / x.sum(), axis=1)\n",
    "    ratio.plot(kind='bar', stacked=True, ax=axes[i])\n",
    "    axes[i].set_title(f'{column} vs y')\n",
    "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "- Campaign calls appear to have higher success with customers when \n",
    "    - calls are made in dec, jun, sept, oct months\n",
    "    - calls are made on mobiles\n",
    "    - calls are made to students or retired\n",
    "    - calls are made to customers with prior success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the success of campaigns with those customers who the bank had success before\n",
    "\n",
    "bank_prevoutcome = bankdata[(bankdata['poutcome'] == 'success') | (bankdata['poutcome'] == 'failure')][['poutcome', 'y']]\n",
    "bank_prevoutcome.head(3)\n",
    "\n",
    "sns.histplot(data=bank_prevoutcome, x='poutcome', hue='y', multiple='stack')\n",
    "\n",
    "returned_customers = len(bankdata[(bankdata.poutcome=='success') & (bankdata.y=='yes')])/len(bankdata[bankdata.poutcome=='success'])\n",
    "print('Returning customers who has subscribed to the new term deposit: {}%'.format(round(returned_customers*100)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Repeat/Returning customers subscribed more to the term deposit </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare the number of calls made across months, to see if the highest number of calls are made in months with high chance of success\n",
    "\n",
    "sns.countplot(x='month', hue='y', data=bankdata)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred> \n",
    "- May, June, July, August: Low conversion rates These months exhibit the highest number of contacts (\"no\" subscriptions) and some of the lowest rates of \"yes\" subscriptions. \n",
    "- March, September, October, December: High Conversion Rates. Note: These months have much fewer contacts overall than the summer months.\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4: Understanding the Task\n",
    "\n",
    "After examining the description and data, your goal now is to clearly state the *Business Objective* of the task.  State the objective below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Objective\n",
    "<font color=darkred>\n",
    "Create a ML model that can help predict success rates for calls made during a marketing campaign. Determine which attributes of customer, campaign or social/economic attributes have the highest influence on the success of customers subscribing to a term deposit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5: Engineering Features\n",
    "\n",
    "Now that you understand your business objective, we will build a basic model to get started.  Before we can do this, we must work to encode the data.  Using just the bank information features, prepare the features and target column for modeling with appropriate encoding and transformations.\n",
    "\n",
    "<font color=darkred>\n",
    "\n",
    "- drop the duration feature\n",
    "- change the education feature to an ordinal (in the pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6: Train/Test Split\n",
    "\n",
    "With your data prepared, split it into a train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bankdata.drop(columns = ['y', 'y_numeric'])  \n",
    "y = bankdata['y']\n",
    "\n",
    "# categorical columns\n",
    "X_encoded = pd.get_dummies(X)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale only numerical columns\n",
    "numerical_cols = X_encoded.select_dtypes(include=['int64', 'float64']).columns\n",
    "X_encoded[numerical_cols] = scaler.fit_transform(X_encoded[numerical_cols])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.3, random_state=0)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample for the minority class\n",
    "undersampler = RandomUnderSampler(random_state=0)\n",
    "\n",
    "# Apply the undersampler to the training data\n",
    "X_train_undersampled, y_train_undersampled = undersampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the new class distribution\n",
    "print(f'Class distribution after undersampling:\\n{y_train_undersampled.value_counts()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversample the minority class using SMOTE\n",
    "smote = SMOTE(random_state=0)  \n",
    "\n",
    "X_train_oversample, y_train_oversample = smote.fit_resample(X_train, y_train) \n",
    "\n",
    "# after oversampling the minority class\n",
    "print(f'After balancing the target variable is: {y_train_oversample.value_counts()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPER FUNCTIONS\n",
    "\n",
    "#empty dataframe to store the results of all gridsearch modelevaluations\n",
    "models_evaluated = pd.DataFrame()\n",
    "\n",
    "# Fit the grid\n",
    "def fit_grid(grid, X_train, y_train):\n",
    "    start = time.time()\n",
    "    grid.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    fitTime = end - start\n",
    "    return round(fitTime,2)\n",
    "\n",
    "# Predict using the grid\n",
    "def predict_grid(grid, X_test):\n",
    "    start = time.time()\n",
    "    y_pred = grid.predict(X_test)\n",
    "    end = time.time()\n",
    "    predictTime = end - start\n",
    "    return y_pred, round(predictTime,2)\n",
    "\n",
    "# Extract scores from the models, and print confusion matrix\n",
    "\n",
    "def get_scores_and_displaycm(fitted_grid, model_prefix, y_test, y_pred, fitTime, predictTime):\n",
    "\n",
    "    _classes = fitted_grid.best_estimator_.named_steps[model_prefix].classes_\n",
    "    cm = confusion_matrix(y_test, y_pred, labels = _classes)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = cm,display_labels = _classes)\n",
    "    # show the plot    \n",
    "    plt.figure(figsize=(3, 3))\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, pos_label='yes')\n",
    "    precision = precision_score(y_test, y_pred, pos_label='yes')\n",
    "    specificity = specificity_score(y_test, y_pred, pos_label='yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='yes')\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    pred = fitted_grid.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_test, pred, pos_label='yes')\n",
    "    grid_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # find the grid fit time for the best model\n",
    "    grid_fit_time_rank1_model = pd.DataFrame(fitted_grid.cv_results_).query('rank_test_score == 1').mean_fit_time.values[0]\n",
    "    \n",
    "    return {'model': model_prefix, \n",
    "            'test accuracy': round(accuracy,3),\n",
    "            'precision': round(precision,3), \n",
    "            'recall': round(recall,3),\n",
    "            'specificity': round(specificity,3),\n",
    "            'f1': round(f1,3),\n",
    "            'AUC': round(grid_auc,3),\n",
    "            'grid total fit time': round(fitTime,3),\n",
    "            'best model mean fit time': round(grid_fit_time_rank1_model,3),\n",
    "            'grid predict time': round(predictTime,3),\n",
    "            'best params': fitted_grid.best_params_\n",
    "}\n",
    "\n",
    "def fit_predict_evaluate(grid, model_name, X_train, y_train, X_test, y_test):    \n",
    "    \n",
    "    #fit the grid\n",
    "    fitTime = fit_grid(grid, X_train, y_train)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred, predictTime = predict_grid(grid, X_test)\n",
    "\n",
    "    # show confusion matrix and other scores\n",
    "    dict = get_scores_and_displaycm(grid, model_name, y_test, y_pred, fitTime, predictTime)\n",
    "\n",
    "    # returns the results/scores of this evaluation\n",
    "    return dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7: A Baseline Model\n",
    "\n",
    "Before we build our first model, we want to establish a baseline.  What is the baseline performance that our classifier should aim to beat?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = DummyClassifier(strategy='most_frequent').fit(X_train, y_train)\n",
    "print (dc.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8: A Basic Model - Logistic Regression\n",
    "\n",
    "Use Logistic Regression to build a basic model on your data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, random_state=42, n_jobs=-1, max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_score = lr.decision_function(X_train)\n",
    "pred = lr.predict(X_test)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_train, y_score, pos_label='yes')\n",
    "\n",
    "grid_auc = auc(fpr, tpr)\n",
    "\n",
    "print('AUC: {}'.format(auc(fpr, tpr)))\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Logistic Regression\n",
    "\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>Primary goal is to improve F1-score and recall metric. While a high precision is important, a higher recall is more important so we do not turn away customers who could have purchased the term deposits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, pred)\n",
    "ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   get the feature names\n",
    "feature_names = lr.feature_names_in_\n",
    "\n",
    "# clean the feature names\n",
    "clean_feature_names = [name.split('__')[-1] for name in feature_names]\n",
    "\n",
    "# get the coefficients\n",
    "coefficients = lr.coef_[0]\n",
    "\n",
    "# convert the coefficients to odds ratio\n",
    "coefficients = np.exp(coefficients)\n",
    "\n",
    "coefficients_df = pd.DataFrame({'feature': clean_feature_names, 'coefficient': coefficients})\n",
    "\n",
    "coefficients_df.sort_values('coefficient', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Evaluate KNN, LR, SVM and DT with default parameters for balanced (under and oversample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(fit_intercept=False, random_state=42, n_jobs=-1, max_iter=10000) \n",
    "svm = SVC()\n",
    "dt = DecisionTreeClassifier()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "classifiers = [lr, svm, dt, knn]\n",
    "classifiers_names = ['Logistic Regression', 'SVM','Decision Tree', 'KNN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing classifiers with default parameters and with balanced dataset (over sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(classifiers)):\n",
    "    \n",
    "    #fit the grid\n",
    "    fitTime = fit_grid(classifiers[i], X_train_oversample, y_train_oversample)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred, predictTime = predict_grid(classifiers[i], X_test)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, pos_label='yes')\n",
    "    precision = precision_score(y_test, y_pred, pos_label='yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='yes')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    classifier_metrics = {'Classifier': classifiers_names[i], 'accuracy': accuracy,\n",
    "                          'F1-Score': f1, 'Precision': precision, 'Recall': recall, \n",
    "                          'Fit Time': fitTime}\n",
    "    \n",
    "    scores.append(classifier_metrics)\n",
    "    \n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing classifiers with balanced variables and with balanced dataset (under sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for i in range(len(classifiers)):\n",
    "\n",
    "    #fit the grid\n",
    "    fitTime = fit_grid(classifiers[i], X_train_undersampled, y_train_undersampled)\n",
    "\n",
    "    # make predictions\n",
    "    y_pred, predictTime = predict_grid(classifiers[i], X_test)\n",
    "\n",
    "    recall = recall_score(y_test, y_pred, pos_label='yes')\n",
    "    precision = precision_score(y_test, y_pred, pos_label='yes')\n",
    "    f1 = f1_score(y_test, y_pred, pos_label='yes')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    classifier_metrics = {'Classifier': classifiers_names[i], 'accuracy': accuracy,\n",
    "                          'F1-Score': f1, 'Precision': precision, 'Recall': recall, \n",
    "                          'Fit Time': fitTime}\n",
    "    \n",
    "    scores.append(classifier_metrics)\n",
    "    \n",
    "scores_df = pd.DataFrame(scores)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "#### Undersampling has better recall scores for all the models ~ 63% \n",
    "\n",
    "**Logistic Regression** and **SVM** best performance and are pretty close on F1-Score. We can do GridSearchCV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10: Logistic Regression GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'lr__solver': ['lbfgs', 'liblinear'],\n",
    "                   'lr__C': [0.0001, 0.0001, 0.001, 1.0]}\n",
    "\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model\n",
    "\n",
    "lr_pipe = Pipeline([('scaler', StandardScaler()),('lr', LogisticRegression(fit_intercept=False, \n",
    "                                                                           random_state=42, \n",
    "                                                                           max_iter=max_iterations))])\n",
    "\n",
    "#lr_grid = GridSearchCV(lr_pipe, params, cv=5, scoring='roc_auc', n_jobs=10, verbose=1)\n",
    "lr_grid = GridSearchCV(lr_pipe, params, cv=5, n_jobs=10, verbose=1)\n",
    "\n",
    "\n",
    "# fit and evaluate the model\n",
    "dict = fit_predict_evaluate(lr_grid, 'lr', X_train_undersampled, y_train_undersampled, X_test, y_test)\n",
    "\n",
    "models_evaluated = pd.concat([models_evaluated, pd.DataFrame([dict])], ignore_index=True)\n",
    "models_evaluated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature names\n",
    "feature_names = lr_grid.best_estimator_.feature_names_in_\n",
    "\n",
    "# clean the feature names\n",
    "clean_feature_names = [name.split('__')[-1] for name in feature_names]\n",
    "clean_feature_names[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "Logistic regression provides Log odds. Convert Log odds to odds Ratio and determine the top 10 coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the coefficients\n",
    "coefficients = lr_grid.best_estimator_.named_steps[\"lr\"].coef_[0]\n",
    "\n",
    "# convert the coefficients to odds ratio\n",
    "coefficients = np.exp(coefficients)\n",
    "\n",
    "# converting coefficients into df \n",
    "lr_results = pd.DataFrame({\"columns\": clean_feature_names, \"values\" : coefficients}).sort_values(by = \"values\", ascending = False)\n",
    "\n",
    "# bar plot\n",
    "lr_results.head(10).plot(kind='bar', x='columns', y='values', legend=False, figsize=(8, 8))\n",
    "\n",
    "# Adding labels and title to the plot\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "Odds of success depend on consumer price index, euribor rates and success of prior outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results.tail(10).sort_values(by= 'values', ascending = True)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GridSearchCV for the Decision Tree model\n",
    "\n",
    "params = {'dt__min_impurity_decrease': [0.001, 0.01, 0.1],\n",
    "         'dt__max_depth': [6,8,10],\n",
    "         'dt__min_samples_split': [0.1, 0.05]}\n",
    "\n",
    "#params = {'dt__max_depth': [2,4,6,8,10]}\n",
    "\n",
    "# transformer = make_column_transformer(\n",
    "#     (OneHotEncoder(drop='if_binary'), [col for col in categorical_columns if col != 'education']),\n",
    "#     (OrdinalEncoder(categories=[['illiterate', 'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'professional.course', 'university.degree', 'unknown']]), ['education'])\n",
    "# )\n",
    "\n",
    "dt_pipe = Pipeline([('dt', DecisionTreeClassifier(random_state = 42))])\n",
    "#dt_grid = GridSearchCV(estimator=dt_pipe, param_grid=params, scoring='roc_auc', n_jobs=10, verbose=3)\n",
    "\n",
    "dt_grid = GridSearchCV(estimator=dt_pipe, param_grid=params, n_jobs=10, verbose=2)\n",
    "\n",
    "dt_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and evaluate the model\n",
    "dict = fit_predict_evaluate(dt_grid, 'dt', X_train_undersampled, y_train_undersampled, X_test, y_test)\n",
    "\n",
    "models_evaluated = pd.concat([models_evaluated, pd.DataFrame([dict])], ignore_index=True)\n",
    "models_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export the tree\n",
    "\n",
    "feature_names = dt_grid.best_estimator_.feature_names_in_\n",
    "\n",
    "# clean the feature names\n",
    "clean_feature_names = [name.split('__')[-1] for name in feature_names]\n",
    "print(clean_feature_names)\n",
    "\n",
    "dt = dt_grid.best_estimator_.named_steps['dt']\n",
    "\n",
    "depth = export_text(dt, feature_names=clean_feature_names)\n",
    "export_text(dt, feature_names=clean_feature_names, show_weights=True)\n",
    "\n",
    "print(depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for the importance of features\n",
    "\n",
    "features_importance = pd.DataFrame({'feature': clean_feature_names, 'importance': dt.feature_importances_})\n",
    "    \n",
    "features_importance.sort_values(by='importance', ascending=False).head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=darkred>\n",
    "\n",
    "Decision tree highlights the importance of the number of employees, consumer confidence index, consumer price index, outcome of previous campaigns, and the euribor 3 month rate in predicting term deposit subscriptions. Lower number of employees and euribor 3 month rate seem to generally correlated to a higher likelihood of subscription\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# Get the best decision tree model\n",
    "dt = dt_grid.best_estimator_.named_steps['dt']\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(dt, feature_names=clean_feature_names, class_names=dt.classes_, filled=True, rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup a GridSearchCV for the SVM model\n",
    "\n",
    "\n",
    "# params = {'svm__kernel': ['rbf', 'poly', 'linear'],\n",
    "#          'svm__gamma': [0.1, 1.0],}\n",
    "\n",
    "# unable to run multiple parameters as it takes a long time to complete the grid search\n",
    "#\n",
    "\n",
    "params = {'svm__kernel': ['linear', 'sigmoid', 'rbf', 'poly'],}\n",
    "\n",
    "svm_pipe = Pipeline([('scaler', StandardScaler()), ('svm', SVC(random_state = 42, probability=True))])\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm_pipe, param_grid=params, scoring='roc_auc', n_jobs=10, verbose=4)\n",
    "\n",
    "svm_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and evaluate the model\n",
    "\n",
    "# fit the model and evaluate the model\n",
    "dict = fit_predict_evaluate(svm_grid, 'svm', X_train_undersampled, y_train_undersampled, X_test, y_test)\n",
    "\n",
    "models_evaluated = pd.concat([models_evaluated, pd.DataFrame([dict])], ignore_index=True)\n",
    "models_evaluated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature names\n",
    "#feature_names = lr_grid.best_estimator_.named_steps['scaler'].get_feature_names_out()\n",
    "feature_names = svm_grid.best_estimator_.feature_names_in_\n",
    "\n",
    "# clean the feature names\n",
    "clean_feature_names = [name.split('__')[-1] for name in feature_names]\n",
    "clean_feature_names[:5]\n",
    "\n",
    "features_importance = svm_grid.best_estimator_.named_steps['svm'].coef_\n",
    "\n",
    "pd.DataFrame({'feature': clean_feature_names, 'importance': features_importance[0]}).sort_values(by='importance', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9: Score the Model\n",
    "\n",
    "What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC curve for all the models\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "lr_label = 'LR AUC:' + str(models_evaluated[models_evaluated['model'] == 'lr']['AUC'].values[0])\n",
    "#knn_label = 'KNN AUC:' + str(models_evaluated[models_evaluated['model'] == 'knn']['AUC'].values[0])\n",
    "dt_label = 'DT AUC:' + str(models_evaluated[models_evaluated['model'] == 'dt']['AUC'].values[0])\n",
    "svm_label = 'SVM AUC:' + str(models_evaluated[models_evaluated['model'] == 'svm']['AUC'].values[0])\n",
    "\n",
    "#RocCurveDisplay.from_estimator(knn_grid, X_test, y_test, pos_label = 'yes', ax = ax, label = knn_label)\n",
    "RocCurveDisplay.from_estimator(lr_grid, X_test, y_test, pos_label = 'yes', ax = ax, label = lr_label)\n",
    "RocCurveDisplay.from_estimator(dt_grid, X_test, y_test, pos_label = 'yes', ax = ax, label =  dt_label    )\n",
    "RocCurveDisplay.from_estimator(svm_grid, X_test, y_test, pos_label = 'yes', ax = ax, label = svm_label) \n",
    "plt.grid()\n",
    "plt.plot(np.arange(0, 1.1, .1), np.arange(0, 1.1, .1), label = 'baseline');\n",
    "plt.title('Using RocCurveDisplay')\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Based on the analysis of ROC curves and AUC scores, Model Performance Assessment is performed based on the analysis of ROC curves and AUC scores. The ROC (Receiver Operating Characteristic) curve visualizes the performance of a binary classifier by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The AUC (Area Under the Curve) score quantifies the overall ability of the model to distinguish between positive and negative instances. A higher AUC indicates better performance.\n",
    "•\tLogistic Regression (LR): AUC = 0.802 - Performs the best among the three models.\n",
    "•\tDecision Tree (DT): AUC = 0.794 - Performs slightly worse than Logistic Regression.\n",
    "•\tSupport Vector Machine (SVM): AUC = 0.776 - Performs the worst among the three models.\n",
    "•\tBaseline: The baseline is the diagonal line, representing random chance (AUC = 0.5). All the models perform significantly better than random chance\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "- Hyperparameter tuning - Further experimentation with hyperparameter tuning for all three models, particularly the Logistic Regression and Decision Tree, to see if you can squeeze out better performance\n",
    "- Interaction Terms: Based on EDA (especially the correlations and bar charts), create interaction terms between features that seem to have a combined effect on the target variable.\n",
    "- Polynomial Features: Consider adding polynomial features to capture non-linear relationships.\n",
    "- Feature Selection/Dimensionality Reduction:\n",
    "- Regularization: For Logistic Regression, experiment with L1 (Lasso) or L2 (Ridge) regularization to reduce overfitting and potentially improve generalization.\n",
    "- PCA/Feature Importance: Use PCA or feature importance from a tree-based model (e.g., Random Forest) to select the most relevant features and reduce dimensionality.\n",
    "- Subscriptions are noticeably higher when the euribor3m rate is lower. Requires further discovery and understanding.\n",
    "- Recommend incorporating external data sources (e.g., demographic data, economic indicators) to enrich banking feature set\n",
    "- A/B Testing: Once you have a refined model, perform A/B testing on a small segment of your customer base to compare the performance of ML (LR) model-driven marketing strategy against your current approach.\n",
    "- Monitoring: Continuously monitor the performance of the model in a production environment and retrain it periodically with new data to maintain its accuracy and relevance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
